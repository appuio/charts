replicaCount: 1

image:
  registry: ghcr-docker-remote.artifactory.swisscom.com
  repository: vshn/haproxy-with-mysql
  tag: 1.0.0
  pullPolicy: IfNotPresent

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: haproxy
    # kubernetes.io/tls-acme: "true"

  ## Hosts for the ingress
  hosts:
    # - one.example.org
    # - two.example.org

  ## TLS configuration
  tls:
    enabled: true
    secretName: # tls-haproxy

## Extra sidecar containers to add to the deployment
sidecarContainers: []

## Affinity for pod assignment. Evaluated as a template.
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

service:
  port: 30636
  type: ClusterIP
  ## Extra ports to add to the service (e.g. for sidecar containers)
  additionalPorts: []

haproxy:
  config: galerak8s
  frontendPort: 30636

  check:
    existingSecret:
      name: "" # Use existing secret with authentication credentials for checks.
      key: "auth-credentials"

  securityContext: {}
    # runAsUser: 1000
    # fsGroup: 1000

  ldapTls:
    certificatePath: /etc/ssl/certs/ca-certificates.crt
    # backend: ldap-example.org

  galera:
    balance: source # see http://cbonte.github.io/haproxy-dconv/1.9/configuration.html#4-balance
    timeout:
      connect: 5s
      client: 10800s
      server: 10800s
    check:
      enabled: true
      mysql:
        enabled: true # see http://cbonte.github.io/haproxy-dconv/1.9/configuration.html#option%20mysql-check
        user: haproxy
    nodes: []
    # - address: galera-node-1
    #   port: 3306
    #   backup: false
    metrics:
      enabled: false
      exposeLoadbalancer: true

  galerak8s:
    balance: first # see http://cbonte.github.io/haproxy-dconv/1.9/configuration.html#4-balance
    timeout:
      connect: 5s
      client: 10800s
      server: 10800s
    check:
      enabled: true
      mysql:
        enabled: true # see http://cbonte.github.io/haproxy-dconv/1.9/configuration.html#option%20mysql-check
        user: haproxy
    dnsservicename: mycluster-mariadb-galera-headless
    port: 3306
    nodeCount: 3
    metrics:
      enabled: false
      exposeLoadbalancer: true

  redisk8s:
    timeout:
      connect: 5s
      client: 60s
      server: 60s
    check:
      enabled: true
      redis:
        auth: ""
    dnsservicename: redis-access-headless
    port: 6379
    nodeCount: 3
    metrics:
      enabled: false
      exposeLoadbalancer: true

  filterproxy:
    # Enables exposing an [exporter-filterproxy](https://github.com/vshn/exporter-filterproxy) that will be filtered using the namspace
    enabled: false
    # The URL of the exporter-filterproxy to expose
    url: ""

metrics:
  enabled: true

  serviceMonitor:
    enabled: false
    # namespace: monitoring
    # interval: 10s
    selector:
      prometheus: kube-prometheus

    ## RelabelConfigs to apply to samples before scraping
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
    ## Value is evalued as a template
    ##
    relabelings: []

    ## MetricRelabelConfigs to apply to samples before ingestion
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
    ## Value is evalued as a template
    ##
    metricRelabelings: []
    #  - sourceLabels:
    #      - "__name__"
    #    targetLabel: "__name__"
    #    action: replace
    #    regex: '(.*)'
    #    replacement: 'example_prefix_$1'

  prometheusRule:
    enabled: false
    additionalLabels: {}
    #namespace: ""
    # rules:
    # - alert: redis_no_backends
    #   expr: haproxy_backend_active_servers{proxy="redis"} < 1
    #   for: 15s
    #   labels:
    #     severity: page
    #   annotations:
    #     summary: HAProxy reports all servers are unhealthy for redis.
    rules: []

  service:
    type: ClusterIP
    ## Use serviceLoadBalancerIP to request a specific static IP,
    ## otherwise leave blank
    # loadBalancerIP:
    annotations: {}
    labels: {}

podDisruptionBudget:
  ## Specifies whether a Pod disruption budget should be created
  ##
  create: true
  # minAvailable: 1
  maxUnavailable: 1

resources:
  limits:
    cpu: 100m
    memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi
